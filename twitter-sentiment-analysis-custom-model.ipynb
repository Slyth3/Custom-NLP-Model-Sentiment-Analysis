{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Summary\n",
    "Train model to predict sentiment analysis. This model will the be used to predict Tweets that reference one of the top 5 banks in South Africa. \n",
    "\n",
    "Training: I used mutiple datasets to do this with Sentiment 140 being the creates contributor of tweets (1.6 million) \n",
    "However this was automatically labled (using emoticons) and doesnt have neutral tweets labled \n",
    "\n",
    "**Note** Proof of concept version was completed using a [pretrained model](https://www.kaggle.com/slythe/sentiment-analysis-with-twint-textblob-poc) (Textblob) \n",
    "\n",
    "## Datasets used\n",
    "1. [Sentiment140](https://www.kaggle.com/milobele/sentiment140-dataset-1600000-tweets)\n",
    "1. [Twitter and Reddit](https://www.kaggle.com/cosmos98/twitter-and-reddit-sentimental-analysis-dataset) \n",
    "1. [US airlines](https://www.kaggle.com/crowdflower/twitter-airline-sentiment) \n",
    "1.[Apple sentiment](https://www.kaggle.com/slythe/apple-twitter-sentiment-crowdflower) \n",
    "\n",
    "## Known issues with sentiment analysis:\n",
    "* Sarcasm - \"thanks FNB, now I cant open my account cause its frozen\" \n",
    "* Comparison of entities  - \"Capitec is the worst, you should use Standard Bank\" \n",
    "* Training data on non-South African tweets  - Jargon and lingo is different\n",
    "* Language usage - multiple languages are used in South Africa\n",
    "\n",
    "Reference notebooks:\n",
    "* [Full sentiment analysis](https://www.kaggle.com/paoloripamonti/twitter-sentiment-analysis/notebook) \n",
    "* [beginners notebook](https://www.kaggle.com/stoicstatic/twitter-sentiment-analysis-for-beginners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://storage.ning.com/topology/rest/1.0/file/get/3780584426?profile=original\" width=\"1000\" height=\"800\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = \"https://storage.ning.com/topology/rest/1.0/file/get/3780584426?profile=original\",width = 1000, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "\n",
    "#preprocessing and scoring\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, recall_score, precision_score\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "#models and algos\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "##customer pipeline function\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "#Feature Extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on stopwords\n",
    "Removal of stop words seems to do more harm than good, many of the sentences lose their meaning. \"not\" and \"nor\" are particularly an issue as well as many of the prepositions \\ \n",
    "\n",
    "**ie.**\n",
    "> what is Apple doing, they won't do well  -->>  Apple well \\\n",
    "> I'm against Samsung  -->>  Samsung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and setup datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./input/training.1600000.processed.noemoticon.csv\",encoding=\"Latin-1\" ,names=[\"polarity\",\"id\", \"date\",\"query\", \"user\", \"tweet\"])\n",
    "sentiment140  = pd.read_csv(\"./input/testdata.manual.2009.06.14.csv\",encoding=\"Latin-1\" ,names=[\"polarity\",\"id\", \"date\",\"query\", \"user\", \"tweet\"])\n",
    "apple = pd.read_csv(\"./input/Apple-Twitter-Sentiment-DFE.csv\", encoding=\"Latin-1\")\n",
    "twitter_reddit = pd.read_csv(\"./input/Twitter_Data.csv\")\n",
    "us_airlines =  pd.read_csv(\"./input/Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unnecessary columns\n",
    "train = train[[\"polarity\", \"tweet\"]]\n",
    "sentiment140 = sentiment140[[\"polarity\", \"tweet\"]]\n",
    "apple = apple[[\"sentiment\",\"text\"]]\n",
    "us_airlines = us_airlines[[\"airline_sentiment\", \"text\"]]\n",
    "twitter_reddit = twitter_reddit[[\"category\", \"clean_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "apple.columns = [\"polarity\",\"tweet\"]\n",
    "sentiment140.columns = [\"polarity\",\"tweet\"]\n",
    "us_airlines.columns = [\"polarity\",\"tweet\"]\n",
    "twitter_reddit.columns = [\"polarity\",\"tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace values to have -1 negative, 0 neutral, 1 postive\n",
    "train[\"polarity\"]  = train[\"polarity\"].replace(4,1)\n",
    "train[\"polarity\"]  = train[\"polarity\"].replace(0,-1)\n",
    "\n",
    "sentiment140[\"polarity\"]  = sentiment140[\"polarity\"].replace(4,1)\n",
    "sentiment140[\"polarity\"]  = sentiment140[\"polarity\"].replace(0,-1)\n",
    "sentiment140[\"polarity\"]  = sentiment140[\"polarity\"].replace(2,0)\n",
    "\n",
    "apple[\"polarity\"] = apple[\"polarity\"].replace(\"1\",-1)\n",
    "apple[\"polarity\"] = apple[\"polarity\"].replace(\"3\",0)\n",
    "apple[\"polarity\"] = apple[\"polarity\"].replace(\"5\",1)\n",
    "\n",
    "us_airlines[\"polarity\"] =us_airlines[\"polarity\"].replace(\"negative\",-1)\n",
    "us_airlines[\"polarity\"] =us_airlines[\"polarity\"].replace(\"neutral\",0)\n",
    "us_airlines[\"polarity\"] =us_airlines[\"polarity\"].replace(\"positive\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = apple[apple[\"polarity\"]!= \"not_relevant\"]\n",
    "apple[\"polarity\"] = apple[\"polarity\"].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_reddit.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  1600000\n",
      "sentiment140:  498\n",
      "apple:  3804\n",
      "twitter_reddit:  162969\n",
      "us_airlines:  14640\n"
     ]
    }
   ],
   "source": [
    "print(\"train: \", len(train))\n",
    "print(\"sentiment140: \", len(sentiment140))\n",
    "print(\"apple: \", len(apple))\n",
    "print(\"twitter_reddit: \", len(twitter_reddit))\n",
    "print(\"us_airlines: \", len(us_airlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.concat([train,sentiment140,apple,us_airlines,twitter_reddit],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='polarity', ylabel='count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data = tweets_df , x = \"polarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the sentiment140 training data not including neutral tweets we have a imbalanced dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Features\n",
    "There are a number of additional features that can be added however this can be its own notebook. We will look only at length for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"tweet\"] = tweets_df[\"tweet\"].astype(str)\n",
    "tweets_df.reset_index(drop = True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length  \n",
    "tweets_df[\"length\"] = tweets_df[\"tweet\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>846083.0</td>\n",
       "      <td>77.853270</td>\n",
       "      <td>41.165913</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>60611.0</td>\n",
       "      <td>88.818036</td>\n",
       "      <td>55.568413</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>875217.0</td>\n",
       "      <td>79.383835</td>\n",
       "      <td>43.483240</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count       mean        std  min   25%   50%    75%    max\n",
       "polarity                                                               \n",
       "-1.0      846083.0  77.853270  41.165913  5.0  45.0  72.0  109.0  359.0\n",
       " 0.0       60611.0  88.818036  55.568413  1.0  47.0  75.0  120.0  267.0\n",
       " 1.0      875217.0  79.383835  43.483240  4.0  45.0  72.0  109.0  374.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.groupby(\"polarity\")[\"length\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2496a80bbb0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1495.62x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "sns.displot(data = tweets_df, x= \"length\", hue= \"polarity\" ,palette={-1:\"r\",0:\"b\",1:\"g\"}, bins = 30,aspect= 4, alpha = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):  \n",
    "    pat1 = r'@[^ ]+'                   #@signs and value\n",
    "    pat2 = r'https?://[A-Za-z0-9./]+'  #links\n",
    "    pat3 = r'\\'s'                      #floating s's\n",
    "    pat4 = r'\\#\\w+'                     # hashtags and value\n",
    "    pat5 = r'&amp '\n",
    "    pat6 = r'[^A-Za-z\\s]'         #remove non-alphabet\n",
    "    combined_pat = r'|'.join((pat1, pat2,pat3,pat4,pat5, pat6))\n",
    "    text = re.sub(combined_pat,\"\",text).lower()\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean\n",
    "tweets_df[\"cleaned_tweet\"] = tweets_df[\"tweet\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop empty \n",
    "tweets_df = tweets_df [ ~(tweets_df[\"cleaned_tweet\"] ==\"\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmetization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def tokenize_lem(sentence):\n",
    "    outlist= []\n",
    "    token = sentence.split()\n",
    "    for tok in token:\n",
    "        outlist.append(lem.lemmatize(tok))\n",
    "    return \" \".join(outlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"cleaned_tweet\"] = tweets_df[\"cleaned_tweet\"].apply(tokenize_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "      <th>length</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>115</td>\n",
       "      <td>awww that a bummer you shoulda got david carr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>111</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>89</td>\n",
       "      <td>i dived many time for the ball managed to save...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>47</td>\n",
       "      <td>my whole body feel itchy and like it on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>111</td>\n",
       "      <td>no it not behaving at all im mad why am i here...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                              tweet  length  \\\n",
       "0      -1.0  @switchfoot http://twitpic.com/2y1zl - Awww, t...     115   \n",
       "1      -1.0  is upset that he can't update his Facebook by ...     111   \n",
       "2      -1.0  @Kenichan I dived many times for the ball. Man...      89   \n",
       "3      -1.0    my whole body feels itchy and like its on fire       47   \n",
       "4      -1.0  @nationwideclass no, it's not behaving at all....     111   \n",
       "\n",
       "                                       cleaned_tweet  \n",
       "0  awww that a bummer you shoulda got david carr ...  \n",
       "1  is upset that he cant update his facebook by t...  \n",
       "2  i dived many time for the ball managed to save...  \n",
       "3       my whole body feel itchy and like it on fire  \n",
       "4  no it not behaving at all im mad why am i here...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1777958 entries, 0 to 1781910\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   polarity       float64\n",
      " 1   tweet          object \n",
      " 2   length         int64  \n",
      " 3   cleaned_tweet  object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 67.8+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets_df[[\"cleaned_tweet\",\"length\"]], tweets_df[\"polarity\"], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF \n",
    "vectorise the tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(X_train[\"cleaned_tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v = tfidf.transform(X_train[\"cleaned_tweet\"])\n",
    "X_test_v = tfidf.transform(X_test[\"cleaned_tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600162, 432733)\n",
      "(177796, 432733)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_v.shape)\n",
    "print(X_test_v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add TFIDF to tweets vector and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler2 = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit([X_train[\"length\"]])\n",
    "scaler2.fit([X_test[\"length\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_len = scaler.transform([X_train[\"length\"]])\n",
    "X_train_len = X_train_len.reshape( X_train_v.shape[0], 1)\n",
    "\n",
    "X_train = scipy.sparse.hstack([X_train_v,X_train_len], format = \"csr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_len = scaler2.transform([X_test[\"length\"]])\n",
    "X_test_len = X_test_len.reshape(X_test_v.shape[0], 1)\n",
    "\n",
    "X_test = scipy.sparse.hstack([X_test_v,X_test_len], format = \"csr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MinMaxScaler = scaler.fit_transform([tweets_df[\"length\"]])\\nMinMaxScaler = MinMaxScaler.reshape( tweets_v.shape[0], 1)\\ntweets_v_scaled = scipy.sparse.hstack([tweets_v,MinMaxScaler], format = \"csr\")'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"MinMaxScaler = scaler.fit_transform([tweets_df[\"length\"]])\n",
    "MinMaxScaler = MinMaxScaler.reshape( tweets_v.shape[0], 1)\n",
    "tweets_v_scaled = scipy.sparse.hstack([tweets_v,MinMaxScaler], format = \"csr\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms used:\n",
    "* Random Forest\n",
    "* LinearSVC\n",
    "* Naive Bayes (Bernoulini and Multinomial)\n",
    "* XGBoost\n",
    "* Logistic Regression\n",
    "* Ridge \n",
    "\n",
    "### Out-the-box models for comparison:\n",
    "1. Textblob \n",
    "1. Vader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "Due to the time some of these models took to run, the tuning for the below models were was done outside Kaggle and as a result some parameter iterations were reduced:\n",
    "\n",
    "#### params per model\n",
    "* LogisticRegression(C=5, max_iter=10000, solver='sag')\n",
    "* LinearSVC(C=1)\n",
    "* RidgeClassifier(alpha=3)\n",
    "* BernoulliNB(alpha=1)\n",
    "* MultinomialNB(alpha=0.01)\n",
    "* XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\\n colsample_bynode=1, colsample_bytree=1, eta=0.5, gamma=0,\\n gpu_id=-1, importance_type='gain', interaction_constraints='',\\n learning_rate=0.5, max_delta_step=0, max_depth=9,\\n min_child_weight=1, missing=nan, monotone_constraints='()',\\n n_estimators=500, n_jobs=4, num_parallel_tree=1,\\n objective='multi:softprob', random_state=0, reg_alpha=0,\\n reg_lambda=1, scale_pos_weight=None, subsample=1,\\n tree_method='exact', validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gen_params = {\"alpha\":[0.001,0.01,1,3,4,5]}\\n\\nxgb_params={\\'eta\\': [0.5, 1, 2, 3], \\n            \\'max_depth\\': [None, 3, 5, 7, 9],\\n                         \\n            \\'n_estimators\\': [50, 100, 150, 200, 300, 500]\\n           }\\nlnSVC_params = {\\n    \"C\": [0.01,1,3,4,5,10]\\n}\\nlogr_params = {\\n    \"penalty\": [\"l2\" ,\"l1\", \"none\"],\\n    \"C\": [1,3,4,5],\\n    \"max_iter\": [5000,10000]\\n}\\n\\nforest_params = {\"n_estimators\": [50, 100],\\n                 \"max_depth\" : [1,5, 10]\\n}'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameters tested outside Kaggle \n",
    "'''gen_params = {\"alpha\":[0.001,0.01,1,3,4,5]}\n",
    "\n",
    "xgb_params={'eta': [0.5, 1, 2, 3], \n",
    "            'max_depth': [None, 3, 5, 7, 9],\n",
    "                         \n",
    "            'n_estimators': [50, 100, 150, 200, 300, 500]\n",
    "           }\n",
    "lnSVC_params = {\n",
    "    \"C\": [0.01,1,3,4,5,10]\n",
    "}\n",
    "logr_params = {\n",
    "    \"penalty\": [\"l2\" ,\"l1\", \"none\"],\n",
    "    \"C\": [1,3,4,5],\n",
    "    \"max_iter\": [5000,10000]\n",
    "}\n",
    "\n",
    "forest_params = {\"n_estimators\": [50, 100],\n",
    "                 \"max_depth\" : [1,5, 10]\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold =StratifiedKFold(n_splits=5,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = pd.DataFrame(columns=[\"model_f1_train\",\"params_used\", \"f1\",\"precision\",\"recall\"])\n",
    "\n",
    "\n",
    "def model_prediction(model, params):\n",
    "    \n",
    "    model = GridSearchCV(model, param_grid= params, cv= kfold)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print (\"Model and params: \", model.best_estimator_, model.best_params_) \n",
    "    print(\"\\n\")\n",
    "    print(\"Train score: \", model.best_score_)\n",
    "    print(\"test score: \",accuracy_score(y_test,y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(\"Test Report:\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    return y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_scoring(y_pred, model):\n",
    "    global y_test\n",
    "    global model_score\n",
    "    \n",
    "    df = pd.DataFrame(data = [[model.best_score_,\n",
    "                           model.best_params_,\n",
    "                           f1_score(y_test,y_pred,average=\"macro\"),\n",
    "                           precision_score(y_test,y_pred,average=\"macro\"),\n",
    "                           recall_score(y_test,y_pred,average=\"macro\")\n",
    "                          ]] , \n",
    "                  columns =model_score.columns, \n",
    "                  index=[str(model.best_estimator_)])\n",
    "    model_score = model_score.append ( df )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Parameters\n",
    "gen_params = {\"alpha\":[1,3]}\n",
    "xgb_params = {\n",
    "        'n_estimators': [200],\n",
    "        'max_depth': [9],\n",
    "        'eta': [0.5],\n",
    "}\n",
    "lnSVC_params = {\n",
    "    \"C\": [1]\n",
    "}\n",
    "logr_params = {\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"C\": [5],\n",
    "    \"max_iter\": [10000]\n",
    "}\n",
    "forest_params = {\"n_estimators\": [100],\n",
    "                 \"max_depth\" : [8]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "#textblob does not required instantiation \n",
    "\n",
    "logr_i = LogisticRegression(solver=\"sag\")\n",
    "ridge_i = RidgeClassifier()                 # L2 regularization\n",
    "lnSVC_i = LinearSVC()\n",
    "naivemulti_i = MultinomialNB()\n",
    "naivebern_i = BernoulliNB()\n",
    "xgb_i = XGBClassifier(#tree_method='gpu_hist'\n",
    "                     )\n",
    "rf_i = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and params:  LogisticRegression(C=5, max_iter=10000, solver='sag') {'C': 5, 'max_iter': 10000, 'penalty': 'l2'}\n",
      "\n",
      "\n",
      "Train score:  0.7864228746576617\n",
      "test score:  0.7871324439244978\n",
      "\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.79      0.77      0.78     84112\n",
      "         0.0       0.84      0.78      0.81      6227\n",
      "         1.0       0.78      0.80      0.79     87457\n",
      "\n",
      "    accuracy                           0.79    177796\n",
      "   macro avg       0.80      0.78      0.79    177796\n",
      "weighted avg       0.79      0.79      0.79    177796\n",
      "\n",
      "Model and params:  RidgeClassifier(alpha=3) {'alpha': 3}\n",
      "\n",
      "\n",
      "Train score:  0.7749534114364387\n",
      "test score:  0.7763560485050283\n",
      "\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.79      0.77      0.78     84112\n",
      "         0.0       0.68      0.45      0.54      6227\n",
      "         1.0       0.77      0.80      0.79     87457\n",
      "\n",
      "    accuracy                           0.78    177796\n",
      "   macro avg       0.75      0.67      0.70    177796\n",
      "weighted avg       0.78      0.78      0.77    177796\n",
      "\n",
      "Model and params:  LinearSVC(C=1) {'C': 1}\n",
      "\n",
      "\n",
      "Train score:  0.7832919419321438\n",
      "test score:  0.7846127021980247\n",
      "\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.79      0.78      0.78     84112\n",
      "         0.0       0.83      0.72      0.77      6227\n",
      "         1.0       0.78      0.80      0.79     87457\n",
      "\n",
      "    accuracy                           0.78    177796\n",
      "   macro avg       0.80      0.77      0.78    177796\n",
      "weighted avg       0.78      0.78      0.78    177796\n",
      "\n",
      "Model and params:  MultinomialNB(alpha=3) {'alpha': 3}\n",
      "\n",
      "\n",
      "Train score:  0.7451982982096469\n",
      "test score:  0.744904272312088\n",
      "\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.76      0.78      0.77     84112\n",
      "         0.0       1.00      0.00      0.00      6227\n",
      "         1.0       0.73      0.77      0.75     87457\n",
      "\n",
      "    accuracy                           0.74    177796\n",
      "   macro avg       0.83      0.52      0.51    177796\n",
      "weighted avg       0.75      0.74      0.73    177796\n",
      "\n",
      "Model and params:  BernoulliNB(alpha=3) {'alpha': 3}\n",
      "\n",
      "\n",
      "Train score:  0.7466856478635194\n",
      "test score:  0.7465747260905757\n",
      "\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.76      0.78      0.77     84112\n",
      "         0.0       0.32      0.11      0.16      6227\n",
      "         1.0       0.74      0.76      0.75     87457\n",
      "\n",
      "    accuracy                           0.75    177796\n",
      "   macro avg       0.61      0.55      0.56    177796\n",
      "weighted avg       0.74      0.75      0.74    177796\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:22:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:21:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:20:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:19:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:18:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Model and params:  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eta=0.5, gamma=0,\n",
      "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.5, max_delta_step=0, max_depth=9,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=200, n_jobs=12, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None) {'eta': 0.5, 'max_depth': 9, 'n_estimators': 200}\n",
      "\n",
      "\n",
      "Train score:  0.7928515987040592\n",
      "test score:  0.7937411415329929\n",
      "\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.81      0.76      0.78     84112\n",
      "         0.0       0.84      0.81      0.83      6227\n",
      "         1.0       0.78      0.82      0.80     87457\n",
      "\n",
      "    accuracy                           0.79    177796\n",
      "   macro avg       0.81      0.80      0.80    177796\n",
      "weighted avg       0.79      0.79      0.79    177796\n",
      "\n",
      "Model and params:  RandomForestClassifier(max_depth=8) {'max_depth': 8, 'n_estimators': 100}\n",
      "\n",
      "\n",
      "Train score:  0.5643047464137576\n",
      "test score:  0.5580496749083219\n",
      "\n",
      "\n",
      "Test Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.87      0.16      0.28     84112\n",
      "         0.0       0.00      0.00      0.00      6227\n",
      "         1.0       0.53      0.98      0.68     87457\n",
      "\n",
      "    accuracy                           0.56    177796\n",
      "   macro avg       0.47      0.38      0.32    177796\n",
      "weighted avg       0.67      0.56      0.47    177796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_pred , logr_m = model_prediction(logr_i,logr_params)\n",
    "ridge_pred, ridge_m = model_prediction(ridge_i,{\"alpha\":[3]})\n",
    "linSVC_pred, lnSVC_m = model_prediction(lnSVC_i, lnSVC_params)\n",
    "naivemulti_pred, naivemulti_m = model_prediction(naivemulti_i, gen_params)\n",
    "naivebern_pred, naivebern_m = model_prediction(naivebern_i, gen_params)\n",
    "xgb_pred, xgb_m = model_prediction(xgb_i, xgb_params)\n",
    "rf_pred, rf_m = model_prediction(rf_i,forest_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [533388, 177796]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-c44655c9329d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-2a14f0270896>\u001b[0m in \u001b[0;36mmodel_scoring\u001b[1;34m(y_pred, model)\u001b[0m\n\u001b[0;32m      5\u001b[0m     df = pd.DataFrame(data = [[model.best_score_,\n\u001b[0;32m      6\u001b[0m                            \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                            \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"macro\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                            \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"macro\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                            \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"macro\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \"\"\"\n\u001b[1;32m-> 1044\u001b[1;33m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[0;32m   1045\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \"\"\"\n\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1169\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1434\u001b[0m                                     pos_label)\n\u001b[0;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1248\u001b[0m                          str(average_options))\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'binary'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \"\"\"\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [533388, 177796]"
     ]
    }
   ],
   "source": [
    "model_scoring(log_pred, logr_m)\n",
    "model_scoring(ridge_pred, ridge_m)\n",
    "model_scoring(linSVC_pred, lnSVC_m)\n",
    "model_scoring(naivemulti_pred, naivemulti_m)\n",
    "model_scoring(naivebern_pred, naivebern_m)\n",
    "model_scoring(xgb_pred, xgb_m)\n",
    "model_scoring(rf_pred, rf_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_f1_train</th>\n",
       "      <th>params_used</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression(C=5, max_iter=10000, solver='sag')</th>\n",
       "      <td>0.786423</td>\n",
       "      <td>{'C': 5, 'max_iter': 10000, 'penalty': 'l2'}</td>\n",
       "      <td>0.793341</td>\n",
       "      <td>0.802866</td>\n",
       "      <td>0.784613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier(alpha=3)</th>\n",
       "      <td>0.774953</td>\n",
       "      <td>{'alpha': 3}</td>\n",
       "      <td>0.701908</td>\n",
       "      <td>0.746598</td>\n",
       "      <td>0.673970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC(C=1)</th>\n",
       "      <td>0.783292</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.780187</td>\n",
       "      <td>0.797435</td>\n",
       "      <td>0.765312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB(alpha=3)</th>\n",
       "      <td>0.745198</td>\n",
       "      <td>{'alpha': 3}</td>\n",
       "      <td>0.506943</td>\n",
       "      <td>0.830172</td>\n",
       "      <td>0.515313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB(alpha=3)</th>\n",
       "      <td>0.746686</td>\n",
       "      <td>{'alpha': 3}</td>\n",
       "      <td>0.560797</td>\n",
       "      <td>0.608912</td>\n",
       "      <td>0.548963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    model_f1_train  \\\n",
       "LogisticRegression(C=5, max_iter=10000, solver=...        0.786423   \n",
       "RidgeClassifier(alpha=3)                                  0.774953   \n",
       "LinearSVC(C=1)                                            0.783292   \n",
       "MultinomialNB(alpha=3)                                    0.745198   \n",
       "BernoulliNB(alpha=3)                                      0.746686   \n",
       "\n",
       "                                                                                     params_used  \\\n",
       "LogisticRegression(C=5, max_iter=10000, solver=...  {'C': 5, 'max_iter': 10000, 'penalty': 'l2'}   \n",
       "RidgeClassifier(alpha=3)                                                            {'alpha': 3}   \n",
       "LinearSVC(C=1)                                                                          {'C': 1}   \n",
       "MultinomialNB(alpha=3)                                                              {'alpha': 3}   \n",
       "BernoulliNB(alpha=3)                                                                {'alpha': 3}   \n",
       "\n",
       "                                                          f1  precision  \\\n",
       "LogisticRegression(C=5, max_iter=10000, solver=...  0.793341   0.802866   \n",
       "RidgeClassifier(alpha=3)                            0.701908   0.746598   \n",
       "LinearSVC(C=1)                                      0.780187   0.797435   \n",
       "MultinomialNB(alpha=3)                              0.506943   0.830172   \n",
       "BernoulliNB(alpha=3)                                0.560797   0.608912   \n",
       "\n",
       "                                                      recall  \n",
       "LogisticRegression(C=5, max_iter=10000, solver=...  0.784613  \n",
       "RidgeClassifier(alpha=3)                            0.673970  \n",
       "LinearSVC(C=1)                                      0.765312  \n",
       "MultinomialNB(alpha=3)                              0.515313  \n",
       "BernoulliNB(alpha=3)                                0.548963  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-the box models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_box_textblob(x):\n",
    "    x = TextBlob(x).sentiment[0]\n",
    "    if x >0:\n",
    "        x = 1\n",
    "    elif x<0:\n",
    "        x = -1\n",
    "    else:\n",
    "        x= 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_box_vader(x):\n",
    "    x = vader.polarity_scores(x)[\"compound\"]\n",
    "    if x >0:\n",
    "        x = 1\n",
    "    elif x<0:\n",
    "        x = -1\n",
    "    else:\n",
    "        x= 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_box_score(y_true, prediction):\n",
    "    global model_score\n",
    "    df = pd.DataFrame(data = [[0,\n",
    "                               0,\n",
    "                               f1_score(y_true,prediction,average=\"macro\"),\n",
    "                               precision_score(y_true,prediction,average=\"macro\"),\n",
    "                               recall_score(y_true,prediction,average=\"macro\")\n",
    "                              ]] ,\n",
    "                      columns=model_score.columns, \n",
    "                      index=[str(prediction.name)])\n",
    "    model_score = model_score.append ( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "textblob_pred = tweets_df[\"cleaned_tweet\"].apply(out_box_textblob)\n",
    "vader_pred = tweets_df[\"cleaned_tweet\"].apply(out_box_vader)\n",
    "\n",
    "out_box_score(tweets_df[\"polarity\"],vader_pred)\n",
    "out_box_score(tweets_df[\"polarity\"],textblob_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all models & vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    logr_m : \"logr_m\",\n",
    "    ridge_m:\"ridge_m\",lnSVC_m:\"lnSVC_m\", naivemulti_m:\"naivemulti_m\", naivebern_m:\"naivebern_m\",xgb_m:\"xgb_m\"\n",
    "              ,rf_m: \"rf_m\"\n",
    "             }\n",
    "for m in model_dict.items():\n",
    "    file = open(f'{m[1]}.pickle','wb')\n",
    "    pickle.dump(m[0], file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save vocabulary \n",
    "with open(\"vocabulary\",\"wb\") as f:\n",
    "    pickle.dump(tfidf.vocabulary_,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier \n",
    "Option ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.ensemble import VotingClassifier\n",
    "vc = VotingClassifier([(\"logr_m\",LogisticRegression()), \n",
    "                       (\"ridge_m\",RidgeClassifier()), \n",
    "                       (\"lnSVC_m\",LinearSVC()), \n",
    "                       (\"ridge_m\",ridge_m),\n",
    "                       (\"naivemulti_m\",MultinomialNB()),\n",
    "                       (\"rf_m\",RandomForestClassifier(),\n",
    "                       (\"xgb_m\",XGBClassifier()\n",
    "                       ))],\n",
    "                      voting = \"hard\")\n",
    "vc.fit(X_train, y_train)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X = tweets_df[\"cleaned_tweet\"]\n",
    "y = tweets_df[\"polarity\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps = [\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"xgb\" , GridSearchCV(xgb_i, param_grid= xgb_params, cv= kfold))\n",
    "]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:53:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:11:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:34:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:12:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:41:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:09:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('xgb',\n",
       "                 GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                              estimator=XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=None,\n",
       "                                                      n_estimators=100,\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      random_state=None,\n",
       "                                                      reg_alpha=None,\n",
       "                                                      reg_lambda=None,\n",
       "                                                      scale_pos_weight=None,\n",
       "                                                      subsample=None,\n",
       "                                                      tree_method=None,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None),\n",
       "                              param_grid={'eta': [0.5], 'max_depth': [9],\n",
       "                                          'n_estimators': [200]}))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.83      0.78      0.81    252947\n",
      "         0.0       0.88      0.84      0.86     18298\n",
      "         1.0       0.80      0.85      0.82    262143\n",
      "\n",
      "    accuracy                           0.82    533388\n",
      "   macro avg       0.84      0.82      0.83    533388\n",
      "weighted avg       0.82      0.82      0.82    533388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('pipemodel_model.pickle','wb')\n",
    "pickle.dump(pipe, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
