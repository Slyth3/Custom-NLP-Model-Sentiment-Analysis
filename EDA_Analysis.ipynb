{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do \n",
    "\n",
    "Sort order Year, month ,day graphs \n",
    "create pie charts of sentiment breakdown(neg,pos, neutral)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Bank Sentiment Analysis \n",
    "\n",
    "## Summary \n",
    "Identify customer sentiment of the top 5 Banks in South Africa via twitter sentiment analysis scoring\n",
    "#### Operations:\n",
    "1. Twint to scrape tweets of the top 5 banks in South Africa \n",
    "*  Standard Bank\n",
    "* Nedbank \n",
    "* Absa \n",
    "* FNB \n",
    "* Capitec \n",
    "\n",
    "2. Clean tweets with WordPunctTokenizer and Regex \n",
    "3. TextBlog to process sentiment of tweets \n",
    "5. Matplotlib / Seaborn to visualise and analyze\n",
    "\n",
    "#### Project 2:\n",
    "Compare results to the Customer Satifaction Index (CSI) and determine if the CSI is a correct reflection of the consumer sentiment\n",
    "-> CSI is obtained by ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twint  guide\n",
    "\n",
    "<b>My reference guide: </b>\n",
    "https://github.com/Slyth3/Twitter_NLP/blob/main/Quick%20Twint%20Code.txt\n",
    "\n",
    "<b> Official Github: </b>\n",
    "https://github.com/twintproject/twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "import pandas as pd\n",
    "import nest_asyncio             \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#optional: for reading and concatenation of previous files\n",
    "import glob                     \n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "\n",
    "#cleaning\n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords             \n",
    "\n",
    "# Sentiment Analysis\n",
    "from textblob import TextBlob\n",
    "\n",
    "#word cloud\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df= pd.concat(map(pd.read_pickle, glob.glob(os.path.join('', \"./Output/OneString/merged_files/full/full*.pickle\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_df = tweets_df.drop(['created_at', 'user_id_str', 'link', 'urls', 'photos', 'video',\n",
    "       'thumbnail', 'retweet','nreplies', 'nretweets', 'quote_url', 'near', 'geo', 'source', 'user_rt_id', 'user_rt',\n",
    "       'retweet_id', 'reply_to', 'retweet_date', 'translate', 'trans_src',\n",
    "       'trans_dest'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweet date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## min date \n",
    "print (\"Earliest date:\",tweets_df[\"date\"].min())\n",
    "print(\"\")\n",
    "print (\"Latest date:\",tweets_df[\"date\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language removal \n",
    "\n",
    "Although the language tag doesnt seem to get it right 100% of the time, we will drop these rows that arent english but keep undefined:\n",
    "* und = undefined --- this will also include tweets with only hashtags so we will keep this\n",
    "* en = english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_df[\"language\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows where language is not english or undefined\n",
    "tweets_df = tweets_df[tweets_df[\"language\"].isin([ 'und', 'en'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary rows \n",
    "* Remove tweets from Bank owned accounts i.e. FNBSA\n",
    "* Remove duplicates where tweet, bank and date are the same \n",
    "* Reindex dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where username is in bank_search\n",
    "tweets_df = tweets_df[ ~tweets_df[\"username\"].str.lower().str.contains('fnb|standardbank|nedbank|absa|capitec',regex = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicated tweets \n",
    "tweets_df = tweets_df.drop_duplicates(subset=['date',\"tweet\"],keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index for visualisation later\n",
    "tweets_df.reset_index(inplace=True, drop = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"date\"] = pd.to_datetime(tweets_df[\"date\"])\n",
    "\n",
    "#set index = date so as to create rolling mean \n",
    "tweets_df = tweets_df.sort_values(\"date\").set_index(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set Bank column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"Bank\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bank_col(df):\n",
    "    #print (df[1]) \n",
    "    bank = df[1]\n",
    "    if \"fnb\" in df[0].lower():\n",
    "        bank =  bank+\"FNB;\"\n",
    "    if \"nedbank\" in df[0].lower():\n",
    "        bank =  bank+\"Nedbank;\"\n",
    "    if \"absa\" in df[0].lower():\n",
    "        bank =  bank+\"ABSA;\"\n",
    "    if \"standard\" in df[0].lower():\n",
    "        bank =  bank+\"Standard;\"\n",
    "    if \"capitec\" in df[0].lower():\n",
    "        bank =  bank+\"Capitec;\"\n",
    "    return bank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"Bank\"] = tweets_df[[\"tweet\",\"Bank\"]].apply(create_bank_col, axis =1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create seperate dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop this warning as the chaining works as intended\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bank Dataframes \n",
    "Standard_df = tweets_df[tweets_df[\"Bank\"].str.contains(\"Standard\")]\n",
    "Standard_df[\"Bank\"]= \"Standard\"\n",
    "\n",
    "FNB_df = tweets_df[tweets_df[\"Bank\"].str.contains(\"FNB\")]\n",
    "FNB_df[\"Bank\"]= \"FNB\"\n",
    "\n",
    "Nedbank_df = tweets_df[tweets_df[\"Bank\"].str.contains(\"Nedbank\")]\n",
    "Nedbank_df[\"Bank\"]= \"Nedbank\"\n",
    "\n",
    "ABSA_df = tweets_df[tweets_df[\"Bank\"].str.contains(\"ABSA\")]\n",
    "ABSA_df[\"Bank\"]= \"ABSA\"\n",
    "\n",
    "Cap_df = tweets_df[tweets_df[\"Bank\"].str.contains(\"Capitec\")]\n",
    "Cap_df[\"Bank\"]= \"Capitec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_df = pd.concat([ABSA_df,Standard_df,Nedbank_df,ABSA_df,Cap_df, FNB_df ], axis =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(tweets_df[\"tweet\"].sample(10)): \n",
    "    print(i, \"    \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install additional libraries for visualisation \n",
    "from collections import Counter\n",
    "\n",
    "import cufflinks as cf\n",
    "from plotly.offline import init_notebook_mode #, plot, iplot, download_plotlyjs\n",
    "init_notebook_mode(connected = True)\n",
    "cf.go_offline()\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Pallette & theme \n",
    "sns.set_theme(rc={\"figure.dpi\":300})\n",
    "                  \n",
    "pal = {\"FNB\":'c', \"Standard\":\"b\",\"ABSA\":\"r\",\"Nedbank\":\"g\",\"Capitec\":\"grey\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize= (15,5))\n",
    "\n",
    "sns.countplot(ax = ax[0], x= Final_df[\"Bank\"], palette= pal,)\n",
    "ax[0].set_title(\"Count of tweets\")\n",
    "\n",
    "sns.barplot(data =Final_df, x = \"Bank\" ,y = \"nlikes\",estimator=np.sum,ci=None, palette=pal)\n",
    "ax[1].set_title(\"Count of likes\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Final_df[[\"tweet\",\"Bank\"]].groupby([\"Bank\"]).count().transpose())\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(Final_df, x=\"Sentiment\", hue=\"Bank\", palette= pal,multiple=\"stack\", alpha = 1)\n",
    "plt.title(\"Count of tweets by sentiment\",fontsize =15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Final_df[[\"tweet\",\"Bank\"]].groupby([\"Bank\"]).count().transpose())\n",
    "\n",
    "fig1 = sns.displot(Final_df, x=\"Sentiment\", col=\"Bank\",col_wrap= 3, hue=\"Bank\", legend=False, palette= pal)\n",
    "fig1.fig.suptitle(\"Count of tweets by Sentiment\",fontsize =15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = sns.displot(data = Final_df[~(Final_df['polarity']==0)], x=\"polarity\",\n",
    "                   col=\"Bank\",\n",
    "                   col_wrap= 3, \n",
    "                   hue=\"Bank\", \n",
    "                   legend=False, \n",
    "                   palette= pal,\n",
    "                   kde = True,\n",
    "                   bins =30)\n",
    "fig1.fig.suptitle(\"Distribution of Sentiment scores(polarity)\",fontsize =15 )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtag analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all hashtags as list\n",
    "def hashlist(df):\n",
    "    hashlist = []\n",
    "    for i in df['hashtags']:\n",
    "        #use ast.literal if you are importing CSV files otherwise just use 'i'\n",
    "        hashlist.extend(i)\n",
    "    return hashlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create hashtag dataframes\n",
    "hash_Absa= pd.DataFrame(Counter(hashlist(ABSA_df)).items()).sort_values(1,ascending=False)\n",
    "hash_NedBank= pd.DataFrame(Counter(hashlist(Nedbank_df)).items()).sort_values(1,ascending=False)\n",
    "hash_StdBank= pd.DataFrame(Counter(hashlist(Standard_df)).items()).sort_values(1,ascending=False)\n",
    "hash_FNB= pd.DataFrame(Counter(hashlist(FNB_df)).items()).sort_values(1,ascending=False)\n",
    "hash_Cap= pd.DataFrame(Counter(hashlist(Cap_df)).items()).sort_values(1,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2,figsize=(15, 10))\n",
    "\n",
    "plt.suptitle(\"Top 5 hashtags per bank\")\n",
    "\n",
    "# ABSA\n",
    "ax[0,0].bar(hash_Absa[0].head(), hash_Absa[1].head(), color = \"r\")\n",
    "ax[0,0].set_title(\"ABSA\")\n",
    "ax[0,0].xaxis.set_tick_params(rotation=45, size = 15)\n",
    "\n",
    "ax[0,1].bar(hash_NedBank[0].head(), hash_NedBank[1].head(), color = \"g\")\n",
    "ax[0,1].set_title(\"Nedbank\")\n",
    "ax[0,1].xaxis.set_tick_params(rotation=45, size = 15)\n",
    "\n",
    "ax[1,0].bar(hash_StdBank[0].head(), hash_StdBank[1].head(), color = \"b\")\n",
    "ax[1,0].set_title(\"Standard Bank\")\n",
    "ax[1,0].xaxis.set_tick_params(rotation=45, size = 15)\n",
    "\n",
    "ax[1,1].bar(hash_FNB[0].head(), hash_FNB[1].head(), color = \"c\")\n",
    "ax[1,1].set_title(\"FNB\")\n",
    "ax[1,1].xaxis.set_tick_params(rotation=45, size = 15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetString_a = \" \".join(list(ABSA_df[\"cleaned_tweet\"])).lower()\n",
    "tweetString_n = \" \".join(list(Nedbank_df[\"cleaned_tweet\"])).lower()\n",
    "tweetString_s = \" \".join(list(Standard_df[\"cleaned_tweet\"])).lower()\n",
    "tweetString_f = \" \".join(list(FNB_df[\"cleaned_tweet\"])).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove Bank name and set wordcloud\n",
    "\n",
    "tweetString_a = re.sub(r\"absa|bank\",\"\",tweetString_a)\n",
    "wordcloud_a = WordCloud(\n",
    "                background_color ='white', \n",
    "                min_font_size = 5).generate(tweetString_a)\n",
    "\n",
    "tweetString_n = re.sub(r\"NedBankSA|Nedbank|nedbank|bank\",\"\",tweetString_n)   \n",
    "wordcloud_n = WordCloud( \n",
    "                background_color ='white', \n",
    "                min_font_size = 5).generate(tweetString_n)\n",
    "\n",
    "tweetString_s = re.sub(r\"standardbankza|standard bank|bank\",\"\",tweetString_s)     \n",
    "wordcloud_s = WordCloud( \n",
    "                background_color ='white', \n",
    "                min_font_size = 5).generate(tweetString_s)\n",
    "\n",
    "tweetString_f = re.sub(r\"FNB|fnb|bank\",\"\",tweetString_f)\n",
    "wordcloud_f = WordCloud( \n",
    "                background_color ='white', \n",
    "                min_font_size = 5).generate(tweetString_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2,figsize=(14, 8),sharey=True)\n",
    "\n",
    "ax[0,0].imshow(wordcloud_s)\n",
    "ax[0,1].imshow(wordcloud_f)\n",
    "ax[1,0].imshow(wordcloud_n)\n",
    "ax[1,1].imshow(wordcloud_a)\n",
    "\n",
    "ax[0,0].axis(\"off\")\n",
    "ax[0,1].axis(\"off\")\n",
    "ax[1,0].axis(\"off\")\n",
    "ax[1,1].axis(\"off\")\n",
    "\n",
    "ax[0,0].set_title(\"StandardBank\")\n",
    "ax[0,1].set_title(\"FNB\")\n",
    "ax[1,0].set_title(\"Nedbank\")\n",
    "ax[1,1].set_title(\"ABSA\")\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall mean sentiment by bank\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Overall mean Sentiment by Bank\")\n",
    "sns.barplot(data = Final_df, x= \"Bank\", y = \"polarity\", palette=pal, ci=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create rolling Mean / Expanding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Std Bank\n",
    "Standard_df['mean'] = Standard_df['polarity'].expanding().mean()\n",
    "Standard_df['rolling'] = Standard_df['polarity'].rolling(\"7d\").mean()\n",
    "\n",
    "#FNB\n",
    "FNB_df['mean'] = FNB_df['polarity'].expanding().mean()\n",
    "FNB_df['rolling'] = FNB_df['polarity'].rolling(\"7d\").mean()\n",
    "\n",
    "#Nebank\n",
    "Nedbank_df['mean'] = Nedbank_df['polarity'].expanding().mean()\n",
    "Nedbank_df['rolling'] = Nedbank_df['polarity'].rolling(\"7d\").mean()\n",
    "\n",
    "#ABSA\n",
    "ABSA_df['mean'] = ABSA_df['polarity'].expanding().mean()\n",
    "ABSA_df['rolling'] = ABSA_df['polarity'].rolling(\"7d\").mean()\n",
    "\n",
    "#Total\n",
    "Cap_df['mean'] = Cap_df['polarity'].expanding().mean()\n",
    "Cap_df['rolling'] = Cap_df['polarity'].rolling(\"7d\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an interactive plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to create our graphs\n",
    "def trace_rolling_creation(df,gname, glinecolor):\n",
    "    return fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x= df.index, \n",
    "            y=df[\"rolling\"], \n",
    "            name=gname,  \n",
    "            mode='lines',\n",
    "            line_color=glinecolor),\n",
    "        secondary_y=False\n",
    ")\n",
    "\n",
    "def trace_count_creation(df,gname, glinecolor):\n",
    "    return fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x= df.index, \n",
    "            y=df[\"polarity\"].rolling('7d').count(), \n",
    "            name=gname,  \n",
    "            fill='tozeroy',line_color=glinecolor), \n",
    "        secondary_y=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_scatter(x=FNB_df.index, y=FNB_df[\"rolling\"], name=\"FNB\", mode='lines',line_color=\"#19D3F3\")\n",
    "fig.add_scatter(x=Standard_df.index, y=Standard_df[\"rolling\"], name=\"Standard Bank\", mode='lines',line_color=\"blue\")\n",
    "fig.add_scatter(x=ABSA_df.index, y=ABSA_df[\"rolling\"], name=\"ABSA\", mode='lines',line_color=\"red\")\n",
    "fig.add_scatter(x=Nedbank_df.index, y=Nedbank_df[\"rolling\"], name=\"Nedbank\", mode='lines',line_color=\"green\")\n",
    "fig.add_scatter(x=Cap_df.index, y=Cap_df[\"rolling\"], name=\"Capitec\", mode='lines',line_color=\"grey\")\n",
    "fig.update_layout(\n",
    "    template = \"seaborn\",\n",
    "    title=\"Rolling 7 day Sentiment (polarity)\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"7 day rolling polarity\",\n",
    "    yaxis_range = [-0.1,0.4],\n",
    "    legend_title=\"Banks\",\n",
    "    font=dict(size=12),\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    margin=dict(l=10,r=10, b=50,t=50, pad=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add traces\n",
    "trace_rolling_creation(ABSA_df, \"ABSA\", '#DC0E1A')\n",
    "trace_rolling_creation(Nedbank_df, \"Nedbank\", '#078a4d')\n",
    "trace_rolling_creation(Standard_df, \"StdBank\", '#054db3')\n",
    "trace_rolling_creation(FNB_df, \"FNB\", '#19D3F3')\n",
    "trace_rolling_creation(Cap_df, \"Capitec\", '#808080')\n",
    "\n",
    "trace_count_creation(ABSA_df, \"ABSA\", 'rgb(220, 14, 26)')\n",
    "trace_count_creation(Nedbank_df, \"NedBank\", 'rgb(7, 138, 77)')\n",
    "trace_count_creation(Standard_df, \"Std Bank\", 'rgb(5, 77, 179)')\n",
    "trace_count_creation(FNB_df, \"FNB\", 'rgb(25, 211, 243)')\n",
    "trace_count_creation(Cap_df, \"Capitec\", 'rgb(128,128,128)')\n",
    "\n",
    "# set figure layout\n",
    "fig.update_layout(\n",
    "    template = \"seaborn\",\n",
    "    title_text=\"Rolling 7d Sentiment vs Count of tweets\",\n",
    "    legend_title=\"Banks\",\n",
    "    font=dict(size=12),\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    margin=dict (l=10,r=10,b=50,t=50, pad=2)\n",
    ")\n",
    "\n",
    "# Set x-axis title\n",
    "fig.update_xaxes(title_text=\"Date\")\n",
    "\n",
    "# Set y-axes titles\n",
    "fig.update_yaxes(title_text=\"Rolling\",range = [-0.1,0.4], secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Count\",range = [0,40000], secondary_y=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year/ Month / Day sentiment comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "sns.lineplot(data = FNB_df.groupby(FNB_df.index.year)[\"polarity\"].mean(), color = \"c\", label = \"FNB\")\n",
    "sns.lineplot(data = Nedbank_df.groupby(Nedbank_df.index.year)[\"polarity\"].mean(), color = \"g\", label = \"Nedbank\")\n",
    "sns.lineplot(data = ABSA_df.groupby(ABSA_df.index.year)[\"polarity\"].mean(), color = \"r\", label = \"ABSA\")\n",
    "sns.lineplot(data = Standard_df.groupby(Standard_df.index.year)[\"polarity\"].mean(), color = \"b\", label = \"StdBank\")\n",
    "sns.lineplot(data = Cap_df.groupby(Cap_df.index.year)[\"polarity\"].mean(), color = \"grey\", label = \"Capitec\")\n",
    "plt.title(\"Sentiment by year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "sns.lineplot(data = FNB_df.groupby(FNB_df.index.month_name())[\"polarity\"].mean(), color = \"c\", label = \"FNB\")\n",
    "sns.lineplot(data = Nedbank_df.groupby(Nedbank_df.index.month_name())[\"polarity\"].mean(), color = \"g\", label = \"Nedbank\")\n",
    "sns.lineplot(data = ABSA_df.groupby(ABSA_df.index.month_name())[\"polarity\"].mean(), color = \"r\", label = \"ABSA\")\n",
    "sns.lineplot(data = Standard_df.groupby(Standard_df.index.month_name())[\"polarity\"].mean(), color = \"b\", label = \"StdBank\")\n",
    "sns.lineplot(data = Cap_df.groupby(Cap_df.index.month_name())[\"polarity\"].mean(), color = \"grey\", label = \"Capitec\")\n",
    "plt.title(\"Sentiment by month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Sentiment by day\")\n",
    "sns.lineplot(data = FNB_df.groupby(FNB_df.index.day_name())[\"polarity\"].mean(), color = \"c\", label = \"FNB\", sort=False)\n",
    "sns.lineplot(data = Nedbank_df.groupby(Nedbank_df.index.day_name())[\"polarity\"].mean(), color = \"g\", label = \"Nedbank\", sort=False)\n",
    "sns.lineplot(data = ABSA_df.groupby(ABSA_df.index.day_name())[\"polarity\"].mean(), color = \"r\", label = \"ABSA\", sort=False)\n",
    "sns.lineplot(data = Standard_df.groupby(Standard_df.index.day_name())[\"polarity\"].mean(), color = \"b\", label = \"StdBank\", sort=False)\n",
    "sns.lineplot(data = Cap_df.groupby(Cap_df.index.day_name())[\"polarity\"].mean(), color = \"grey\", label = \"Capitec\", sort=False)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Sentiment by hour\")\n",
    "sns.lineplot(data = FNB_df.groupby(FNB_df.index.hour)[\"polarity\"].mean(), color = \"c\", label = \"FNB\")\n",
    "sns.lineplot(data = Nedbank_df.groupby(Nedbank_df.index.hour)[\"polarity\"].mean(), color = \"g\", label = \"Nedbank\")\n",
    "sns.lineplot(data = ABSA_df.groupby(ABSA_df.index.hour)[\"polarity\"].mean(), color = \"r\", label = \"ABSA\")\n",
    "sns.lineplot(data = Standard_df.groupby(Standard_df.index.hour)[\"polarity\"].mean(), color = \"b\", label = \"StdBank\")\n",
    "sns.lineplot(data = Cap_df.groupby(Cap_df.index.hour)[\"polarity\"].mean(), color = \"grey\", label = \"Capitec\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
